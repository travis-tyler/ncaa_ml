{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 March Madess ML contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlalchemy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: https://www.kaggle.com/c/ncaam-march-mania-2021/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all CSV files\n",
    "datasets = os.listdir('../resources/kaggle_data/')\n",
    "dfs = {}\n",
    "for file in datasets:\n",
    "    dfs[file[:-4]] = pd.DataFrame(pd.read_csv(f'../resources/kaggle_data/{file}', encoding='cp1252'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preview all DFs\n",
    "# df_list = list(dfs.keys())\n",
    "# for x in df_list:\n",
    "#     print(x)\n",
    "#     print(dfs[x])\n",
    "#     print('\\n-----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create relevant dataframes\n",
    "seed_df = dfs['MNCAATourneySeeds']\n",
    "reg_short_df = dfs['MRegularSeasonCompactResults']\n",
    "tourney_short_df = dfs['MNCAATourneyCompactResults']\n",
    "reg_long_df = dfs['MRegularSeasonDetailedResults']\n",
    "tourney_long_df = dfs['MNCAATourneyDetailedResults']\n",
    "massey_df = dfs['MMasseyOrdinals']\n",
    "teams_df = dfs['MTeams']\n",
    "game_cities_df = dfs['MGameCities']\n",
    "secondary_short_df = dfs['MSecondaryTourneyCompactResults']\n",
    "coaches_df = dfs['MTeamCoaches']\n",
    "submission_example_df = dfs['MSampleSubmissionStage1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamID</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>FirstD1Season</th>\n",
       "      <th>LastD1Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>Akron</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105</td>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "      <td>2000</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TeamID     TeamName  FirstD1Season  LastD1Season\n",
       "0    1101  Abilene Chr           2014          2021\n",
       "1    1102    Air Force           1985          2021\n",
       "2    1103        Akron           1985          2021\n",
       "3    1104      Alabama           1985          2021\n",
       "4    1105  Alabama A&M           2000          2021"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>20</td>\n",
       "      <td>1228</td>\n",
       "      <td>81</td>\n",
       "      <td>1328</td>\n",
       "      <td>64</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1106</td>\n",
       "      <td>77</td>\n",
       "      <td>1354</td>\n",
       "      <td>70</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1112</td>\n",
       "      <td>63</td>\n",
       "      <td>1223</td>\n",
       "      <td>56</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1165</td>\n",
       "      <td>70</td>\n",
       "      <td>1432</td>\n",
       "      <td>54</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1192</td>\n",
       "      <td>86</td>\n",
       "      <td>1447</td>\n",
       "      <td>74</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT\n",
       "0    1985      20     1228      81     1328      64    N      0\n",
       "1    1985      25     1106      77     1354      70    H      0\n",
       "2    1985      25     1112      63     1223      56    H      0\n",
       "3    1985      25     1165      70     1432      54    H      0\n",
       "4    1985      25     1192      86     1447      74    H      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_short_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>FirstDayNum</th>\n",
       "      <th>LastDayNum</th>\n",
       "      <th>CoachName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>reggie_minton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>1103</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>bob_huggins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>1104</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>wimp_sanderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>1106</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>james_oliver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>davey_whitney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  TeamID  FirstDayNum  LastDayNum       CoachName\n",
       "0    1985    1102            0         154   reggie_minton\n",
       "1    1985    1103            0         154     bob_huggins\n",
       "2    1985    1104            0         154  wimp_sanderson\n",
       "3    1985    1106            0         154    james_oliver\n",
       "4    1985    1108            0         154   davey_whitney"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coaches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Tourney</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>Team1Seed</th>\n",
       "      <th>Team2Seed</th>\n",
       "      <th>Team1FirstYear</th>\n",
       "      <th>Team1LastYear</th>\n",
       "      <th>Team2FirstYear</th>\n",
       "      <th>Team2LastYear</th>\n",
       "      <th>WTeam</th>\n",
       "      <th>Team1RankMean</th>\n",
       "      <th>Team2RankMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>20</td>\n",
       "      <td>1228</td>\n",
       "      <td>1328</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1228</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1106</td>\n",
       "      <td>1354</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1106</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1112</td>\n",
       "      <td>1223</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1112</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1165</td>\n",
       "      <td>1432</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1165</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1985</td>\n",
       "      <td>2020</td>\n",
       "      <td>1985</td>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1192</td>\n",
       "      <td>1447</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1192</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169126</th>\n",
       "      <td>2019</td>\n",
       "      <td>146</td>\n",
       "      <td>1120</td>\n",
       "      <td>1246</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1120</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>17.748713</td>\n",
       "      <td>15.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169127</th>\n",
       "      <td>2019</td>\n",
       "      <td>146</td>\n",
       "      <td>1181</td>\n",
       "      <td>1277</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1277</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>1.980769</td>\n",
       "      <td>6.603239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169128</th>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>1277</td>\n",
       "      <td>1403</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1403</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>6.603239</td>\n",
       "      <td>13.330275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169129</th>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>1120</td>\n",
       "      <td>1438</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1438</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>17.748713</td>\n",
       "      <td>3.682186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169130</th>\n",
       "      <td>2019</td>\n",
       "      <td>154</td>\n",
       "      <td>1403</td>\n",
       "      <td>1438</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1438</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>1985</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>13.330275</td>\n",
       "      <td>3.682186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169131 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Season  DayNum  Team1  Team2  Tourney WLoc  WTeamID  ScoreDiff  \\\n",
       "0         1985      20   1228   1328        0    N     1228         17   \n",
       "1         1985      25   1106   1354        0    H     1106          7   \n",
       "2         1985      25   1112   1223        0    H     1112          7   \n",
       "3         1985      25   1165   1432        0    H     1165         16   \n",
       "4         1985      25   1192   1447        0    H     1192         12   \n",
       "...        ...     ...    ...    ...      ...  ...      ...        ...   \n",
       "169126    2019     146   1120   1246        1    N     1120          6   \n",
       "169127    2019     146   1181   1277        1    N     1277          1   \n",
       "169128    2019     152   1277   1403        1    N     1403         10   \n",
       "169129    2019     152   1120   1438        1    N     1438          1   \n",
       "169130    2019     154   1403   1438        1    N     1438          8   \n",
       "\n",
       "        Team1Seed  Team2Seed  Team1FirstYear  Team1LastYear  Team2FirstYear  \\\n",
       "0               3          1            1985           2021            1985   \n",
       "1              30         30            1985           2021            1985   \n",
       "2              10         30            1985           2021            1985   \n",
       "3              30         30            1985           2020            1985   \n",
       "4              16         30            1985           2021            1985   \n",
       "...           ...        ...             ...            ...             ...   \n",
       "169126          5          2            1985           2021            1985   \n",
       "169127          1          2            1985           2021            1985   \n",
       "169128          2          3            1985           2021            1985   \n",
       "169129          5          1            1985           2021            1985   \n",
       "169130          3          1            1985           2021            1985   \n",
       "\n",
       "        Team2LastYear  WTeam  Team1RankMean  Team2RankMean  \n",
       "0                2021      1     500.000000     500.000000  \n",
       "1                2021      1     500.000000     500.000000  \n",
       "2                2021      1     500.000000     500.000000  \n",
       "3                1987      1     500.000000     500.000000  \n",
       "4                2021      1     500.000000     500.000000  \n",
       "...               ...    ...            ...            ...  \n",
       "169126           2021      1      17.748713      15.207700  \n",
       "169127           2021      0       1.980769       6.603239  \n",
       "169128           2021      0       6.603239      13.330275  \n",
       "169129           2021      0      17.748713       3.682186  \n",
       "169130           2021      0      13.330275       3.682186  \n",
       "\n",
       "[169131 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make boolean columns for Tourney\n",
    "reg_short_df['Tourney'] = 0\n",
    "tourney_short_df['Tourney'] = 1\n",
    "\n",
    "# append reg season and tourney DFs\n",
    "combined_df = reg_short_df.append(tourney_short_df)\n",
    "combined_df['ScoreDiff'] = combined_df['WScore'] - combined_df['LScore']\n",
    "\n",
    "# create team 1 and 2 columns based on ID\n",
    "combined_df['Team1'] = np.where(combined_df['WTeamID']<combined_df['LTeamID'],\n",
    "                                combined_df['WTeamID'],\n",
    "                                combined_df['LTeamID'])\n",
    "combined_df['Team2'] = np.where(combined_df['WTeamID']>combined_df['LTeamID'],\n",
    "                                combined_df['WTeamID'],\n",
    "                                combined_df['LTeamID'])\n",
    "\n",
    "combined_df = combined_df[['Season','DayNum','Team1','Team2','Tourney','WLoc','WTeamID','ScoreDiff']]\n",
    "\n",
    "# add team 1 tourney seed column\n",
    "merged_df = pd.merge(combined_df, seed_df, \n",
    "                     how='left', \n",
    "                     left_on=['Season','Team1'], \n",
    "                     right_on=['Season','TeamID'])\\\n",
    "            .drop(columns=['TeamID'])\n",
    "\n",
    "merged_df = merged_df.rename(columns={'Seed':'Team1Seed'})\n",
    "\n",
    "# add team 2 tourney seed column\n",
    "merged_df2 = pd.merge(merged_df, seed_df, \n",
    "                     how='left', \n",
    "                     left_on=['Season','Team2'], \n",
    "                     right_on=['Season','TeamID'])\\\n",
    "            .drop(columns=['TeamID'])\n",
    "\n",
    "merged_df2 = merged_df2.rename(columns={'Seed':'Team2Seed'})\n",
    "\n",
    "# merged_df2['Team1Seed'] = np.where(merged_df2['Tourney']==0, 'N/A', merged_df2['Team1Seed'])\n",
    "# merged_df2['Team2Seed'] = np.where(merged_df2['Tourney']==0, 'N/A', merged_df2['Team2Seed'])\n",
    "\n",
    "# merged_df2 = merged_df2.fillna('N/A')\n",
    "\n",
    "# add first/last D1 year\n",
    "merged_df3 = pd.merge(merged_df2, teams_df, how='left', left_on='Team1', right_on='TeamID')\n",
    "merged_df3 = merged_df3.drop(columns=['TeamID','TeamName'])\n",
    "merged_df3 = merged_df3.rename(columns={'FirstD1Season':'Team1FirstYear','LastD1Season':'Team1LastYear'})\n",
    "\n",
    "merged_df3 = pd.merge(merged_df3, teams_df, how='left', left_on='Team2', right_on='TeamID')\n",
    "merged_df3 = merged_df3.drop(columns=['TeamID','TeamName'])\n",
    "merged_df3 = merged_df3.rename(columns={'FirstD1Season':'Team2FirstYear','LastD1Season':'Team2LastYear'})\n",
    "\n",
    "# winning team boolean\n",
    "merged_df3['WTeam'] = np.where(merged_df2['WTeamID']==merged_df2['Team1'],1,0)\n",
    "\n",
    "# change seed type\n",
    "merged_df3['Team1Seed'] = merged_df3['Team1Seed'].str.strip().str[1:3]\n",
    "merged_df3['Team1Seed'] = np.where(len(merged_df3['Team1Seed'])>2, \n",
    "                                   merged_df3['Team1Seed'].str[:2], \n",
    "                                   merged_df3['Team1Seed'])\n",
    "merged_df3['Team2Seed'] = merged_df3['Team2Seed'].str.strip().str[1:3]\n",
    "merged_df3['Team2Seed'] = np.where(len(merged_df3['Team2Seed'])>2, \n",
    "                                   merged_df3['Team2Seed'].str[:2], \n",
    "                                   merged_df3['Team2Seed'])\n",
    "\n",
    "merged_df3 = merged_df3.fillna('30')\n",
    "\n",
    "merged_df3 = merged_df3.astype({'Team1Seed':'int','Team2Seed':'int'})\n",
    "\n",
    "# merged_df2['Team1Seed'] = np.where(merged_df2['Tourney']==1, merged_df2['Team1Seed'], '0')\n",
    "# merged_df2['Team2Seed'] = np.where(merged_df2['Tourney']==1, merged_df2['Team2Seed'], '0')\n",
    "\n",
    "# add team rank averages\n",
    "massey_season_avg = massey_df.groupby(['Season','TeamID'], as_index=False)['OrdinalRank'].mean()\n",
    "\n",
    "merged_df4 = pd.merge(merged_df3, massey_season_avg, \n",
    "                       how='left', \n",
    "                       left_on=['Season','Team1'], \n",
    "                       right_on=['Season','TeamID'])\n",
    "\n",
    "merged_df5 = pd.merge(merged_df4, massey_season_avg, \n",
    "                       how='left', \n",
    "                       left_on=['Season','Team2'], \n",
    "                       right_on=['Season','TeamID'])\n",
    "\n",
    "merged_df5 = merged_df5.rename(columns={'OrdinalRank_x':'Team1RankMean','OrdinalRank_y':'Team2RankMean'})\\\n",
    "    .drop(columns=['TeamID_x','TeamID_y'])\n",
    "\n",
    "merged_df5 = merged_df5.fillna(500)\n",
    "\n",
    "merged_df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129204, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove Tourney 2015-19 records\n",
    "merged_df5 = merged_df5[['Season','Team1','Team2','Tourney','WLoc',\n",
    "                         'Team1Seed','Team2Seed','Team1RankMean',\n",
    "                         'Team2RankMean','Team1FirstYear','Team2FirstYear','WTeam']]\n",
    "merged_df5 = merged_df5.loc[(merged_df5.Season < 2014) & (merged_df5.Tourney==0)]\n",
    "# merged_df5 = merged_df5.dropna(how='any')\n",
    "merged_df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df4 = merged_df4.astype({'Season':'str','DayNum':'str','Team1':'str','Team2':'str'})\n",
    "# dummies_df = pd.get_dummies(merged_df4[['Season','Team1','Team2','Tourney','WLoc','Team1Seed','Team2Seed','WTeam']])\n",
    "# dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129204, 11)\n",
      "(129204,)\n"
     ]
    }
   ],
   "source": [
    "# select features and target\n",
    "target = merged_df5.pop('WTeam')\n",
    "selected_features = merged_df5\n",
    "\n",
    "print(selected_features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), make_column_selector(dtype_include=np.number)),\n",
    "    (OneHotEncoder(), make_column_selector(dtype_include=object))\n",
    ")\n",
    "\n",
    "#hmmm. maybe 'handle_unknown = \"ignore\"'?'\n",
    "\n",
    "# ct.fit_transform(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Classifier testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.58192777\n",
      "Iteration 2, loss = 0.55745433\n",
      "Iteration 3, loss = 0.55593220\n",
      "Iteration 4, loss = 0.55497414\n",
      "Iteration 5, loss = 0.55450037\n",
      "Iteration 6, loss = 0.55443715\n",
      "Iteration 7, loss = 0.55406040\n",
      "Iteration 8, loss = 0.55377612\n",
      "Iteration 9, loss = 0.55379749\n",
      "Iteration 10, loss = 0.55347778\n",
      "Iteration 11, loss = 0.55339706\n",
      "Iteration 12, loss = 0.55336337\n",
      "Iteration 13, loss = 0.55344847\n",
      "Iteration 14, loss = 0.55336690\n",
      "Iteration 15, loss = 0.55337734\n",
      "Iteration 16, loss = 0.55313997\n",
      "Iteration 17, loss = 0.55291114\n",
      "Iteration 18, loss = 0.55308291\n",
      "Iteration 19, loss = 0.55287725\n",
      "Iteration 20, loss = 0.55285116\n",
      "Iteration 21, loss = 0.55270424\n",
      "Iteration 22, loss = 0.55287867\n",
      "Iteration 23, loss = 0.55278303\n",
      "Iteration 24, loss = 0.55268716\n",
      "Iteration 25, loss = 0.55265379\n",
      "Iteration 26, loss = 0.55259084\n",
      "Iteration 27, loss = 0.55252799\n",
      "Iteration 28, loss = 0.55258846\n",
      "Iteration 29, loss = 0.55248287\n",
      "Iteration 30, loss = 0.55244004\n",
      "Iteration 31, loss = 0.55236336\n",
      "Iteration 32, loss = 0.55230405\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Train score: 0.6783690907402248\n",
      "Test score: 0.6783690907402248\n",
      "Log loss: 11.108846357867689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "# # X, y = make_classification(n_samples=100, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, \n",
    "                                                    target, stratify=target, \n",
    "                                                    random_state=69)\n",
    "\n",
    "clf = make_pipeline(ct, MLPClassifier(random_state=1, max_iter=300, verbose=True))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.predict_proba(X_test)\n",
    "preds = clf.predict(X_test)\n",
    "train_score = clf.score(X_train, y_train)\n",
    "test_score = clf.score(X_test, y_test)\n",
    "loss_score = metrics.log_loss(y_test, preds)\n",
    "\n",
    "print(f'Train score: {test_score}')\n",
    "print(f'Test score: {test_score}')\n",
    "print(f'Log loss: {loss_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_submit(model, df):\n",
    "    '''Creates and formats submission '''\n",
    "    preds = model.predict(df)\n",
    "    prob = [x[1] for x in clf.predict_proba(df)]\n",
    "    \n",
    "    predict_df = pd.DataFrame({'Season':df['Season'],\n",
    "                  'Team1':df['Team1'],\n",
    "                  'Team2':df['Team2'],\n",
    "                  'Pred':preds,\n",
    "                  'Probability':prob}).round(1)\n",
    "\n",
    "    predict_df['ID'] = predict_df['Season'].astype(str) + '_' +\\\n",
    "                       predict_df['Team1'].astype(str) + '_' +\\\n",
    "                       predict_df['Team2'].astype(str)\n",
    "    \n",
    "    return predict_df[['ID','Probability']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11390, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_data = pd.DataFrame(submission_example_df['ID'].str.split('_',expand=True))\n",
    "submit_data.columns = ['Season','Team1','Team2']\n",
    "submit_data = submit_data.astype('int')\n",
    "\n",
    "# make boolean columns for Tourney and WLoc\n",
    "submit_data['Tourney'] = 1\n",
    "submit_data['WLoc'] = 'N'\n",
    "\n",
    "# add team 1 and 2 tourney seed column\n",
    "submit_data2 = pd.merge(submit_data, seed_df, \n",
    "                     how='left', \n",
    "                     left_on=['Season','Team1'], \n",
    "                     right_on=['Season','TeamID'])\\\n",
    "            .drop(columns=['TeamID'])\n",
    "\n",
    "submit_data2 = submit_data2.rename(columns={'Seed':'Team1Seed'})\n",
    "\n",
    "submit_data3 = pd.merge(submit_data2, seed_df, \n",
    "                     how='left', \n",
    "                     left_on=['Season','Team2'], \n",
    "                     right_on=['Season','TeamID'])\\\n",
    "            .drop(columns=['TeamID'])\n",
    "\n",
    "submit_data4 = submit_data3.rename(columns={'Seed':'Team2Seed'})\n",
    "\n",
    "# change seed data type and remove alpha characters\n",
    "submit_data4['Team1Seed'] = submit_data4['Team1Seed'].str.strip().str[1:3]\n",
    "submit_data4['Team1Seed'] = np.where(len(submit_data4['Team1Seed'])>2, \n",
    "                                   submit_data4['Team1Seed'].str[:2], \n",
    "                                   submit_data4['Team1Seed'])\n",
    "submit_data4['Team2Seed'] = submit_data4['Team2Seed'].str.strip().str[1:3]\n",
    "submit_data4['Team2Seed'] = np.where(len(submit_data4['Team2Seed'])>2, \n",
    "                                   submit_data4['Team2Seed'].str[:2], \n",
    "                                   submit_data4['Team2Seed'])\n",
    "\n",
    "# test_data3 = test_data3.fillna('30')\n",
    "\n",
    "submit_data4 = submit_data4.astype({'Team1Seed':'int','Team2Seed':'int'})\n",
    "\n",
    "# add rank data\n",
    "massey_season_avg = massey_df.groupby(['Season','TeamID'], as_index=False)['OrdinalRank'].mean()\n",
    "\n",
    "submit_data4 = pd.merge(submit_data4, massey_season_avg, \n",
    "                       how='left', \n",
    "                       left_on=['Season','Team1'], \n",
    "                       right_on=['Season','TeamID'])\n",
    "\n",
    "submit_data5 = pd.merge(submit_data4, massey_season_avg, \n",
    "                       how='left', \n",
    "                       left_on=['Season','Team2'], \n",
    "                       right_on=['Season','TeamID'])\n",
    "\n",
    "submit_data5 = submit_data5.rename(columns={'OrdinalRank_x':'Team1RankMean','OrdinalRank_y':'Team2RankMean'})\\\n",
    "    .drop(columns=['TeamID_x','TeamID_y'])\n",
    "\n",
    "# test_data5 = test_data5.fillna(500)\n",
    "\n",
    "# add first/last D1 year\n",
    "submit_data5 = pd.merge(submit_data5, teams_df, how='left', left_on='Team1', right_on='TeamID')\n",
    "submit_data5 = submit_data5.drop(columns=['TeamID','TeamName'])\n",
    "submit_data5 = submit_data5.rename(columns={'FirstD1Season':'Team1FirstYear','LastD1Season':'Team1LastYear'})\n",
    "\n",
    "submit_data5 = pd.merge(submit_data5, teams_df, how='left', left_on='Team2', right_on='TeamID')\n",
    "submit_data5 = submit_data5.drop(columns=['TeamID','TeamName'])\n",
    "submit_data5 = submit_data5.rename(columns={'FirstD1Season':'Team2FirstYear','LastD1Season':'Team2LastYear'})\n",
    "\n",
    "# set DF shape\n",
    "submit_data5 = submit_data5[['Season','Team1','Team2','Tourney','WLoc','Team1Seed','Team2Seed','Team1RankMean','Team2RankMean','Team1FirstYear','Team2FirstYear']]\n",
    "submit_data5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create new DF of all potential matchups\n",
    "# # for 2020 NCAA Tourney only\n",
    "\n",
    "# import itertools\n",
    "\n",
    "# all_combos = list(itertools.combinations(teams_dict[i], 2)) \n",
    "# pd.DataFrame(all_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_1107_1112</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_1107_1116</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_1107_1124</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_1107_1125</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_1107_1129</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11385</th>\n",
       "      <td>2019_1449_1459</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11386</th>\n",
       "      <td>2019_1449_1463</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11387</th>\n",
       "      <td>2019_1458_1459</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11388</th>\n",
       "      <td>2019_1458_1463</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>2019_1459_1463</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11390 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  Probability\n",
       "0      2015_1107_1112          0.1\n",
       "1      2015_1107_1116          0.1\n",
       "2      2015_1107_1124          0.1\n",
       "3      2015_1107_1125          0.4\n",
       "4      2015_1107_1129          0.3\n",
       "...               ...          ...\n",
       "11385  2019_1449_1459          0.6\n",
       "11386  2019_1449_1463          0.8\n",
       "11387  2019_1458_1459          0.7\n",
       "11388  2019_1458_1463          0.9\n",
       "11389  2019_1459_1463          0.9\n",
       "\n",
       "[11390 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_submit(clf, submit_data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale data\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # define min max scaler\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# # transform data\n",
    "# X_scaled = scaler.fit_transform(selected_features)\n",
    "\n",
    "# pd.DataFrame(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c5d8c287617d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m             X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n\u001b[0;32m-> 1132\u001b[0;31m                                        multi_output=True)\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'A'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    print(k)\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print('----')\n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "print(1)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=9)\n",
    "print(2)\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(3)\n",
    "preds = knn_model.predict(X_test)\n",
    "print(4)\n",
    "train_score = knn_model.score(X_train, y_train)\n",
    "print(5)\n",
    "test_score = knn_model.score(X_test, y_test)\n",
    "print(6)\n",
    "loss_score = log_loss(y_test, preds)\n",
    "print(7)\n",
    "print(f'Train score: {train_score}')\n",
    "print(f'Test score: {test_score}')\n",
    "print(f'Loss score: {loss_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_submit(knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.predict_proba(X_test)[0:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_submit(model):\n",
    "#     '''Creates and formats submission '''\n",
    "# #     pipeline = make_pipeline(ct, model)\n",
    "    \n",
    "# #     pipeline.fit(X_train, y_train)\n",
    "    \n",
    "#     train_score = clf.score(X_train, y_train)\n",
    "#     test_score = clf.score(X_test, y_test)\n",
    "#     loss_score = metrics.log_loss(y_test, prediction)\n",
    "    \n",
    "#     preds = model.predict(test_data5)\n",
    "#     prob = [x[0] for x in clf.predict_proba(test_data5)]\n",
    "    \n",
    "#     predict_df = pd.DataFrame({'Season':test_data5['Season'],\n",
    "#                   'Team1':test_data5['Team1'],\n",
    "#                   'Team2':test_data5['Team2'],\n",
    "#                   'Pred':preds,\n",
    "#                   'Probability':prob}).round(1)\n",
    "\n",
    "#     predict_df['ID'] = predict_df['Season'].astype(str) + '_' + predict_df['Team1'].astype(str) + '_' + predict_df['Team2'].astype(str)\n",
    "    \n",
    "# #     predict_df['Correct?'] = np.where(predict_df.Pred==predict_df.Answer, 'YES', 'NO')\n",
    "\n",
    "#     print(f'Train score: {test_score}')\n",
    "#     print(f'Test score: {test_score}')\n",
    "#     print(f'Log loss: {loss_score}')\n",
    "# #     print(f\"{(predict_df.loc[predict_df['Correct?']=='YES']['Correct?'].count()/predict_df['Correct?'].count())*100}%\")\n",
    "    \n",
    "#     return predict_df[['ID','Probability']].reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
