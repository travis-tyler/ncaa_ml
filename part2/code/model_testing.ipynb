{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCAA ML contest - Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Season', 'DayNum', 'Team1', 'Team2', 'Tourney', 'WLoc', 'ScoreDiff',\n",
       "       'Team1Seed', 'Team2Seed', 'Team1FirstYear', 'Team1LastYear',\n",
       "       'Team2FirstYear', 'Team2LastYear', 'WTeam', 'Team1RankMean',\n",
       "       'Team2RankMean', 'WinCount_Team1', 'GameCount_Team1', 'AvgScore_Team1',\n",
       "       'Win%_Team1', 'WinCount_Team2', 'GameCount_Team2', 'AvgScore_Team2',\n",
       "       'Win%_Team2', 'LoseCount_Team1', 'AvgFGM_Team1', 'LoseCount_Team2',\n",
       "       'AvgFGM_Team2', 'AvgFGA_Team1', 'AvgFGA_Team2', 'AvgFGM3_Team1',\n",
       "       'AvgFGM3_Team2', 'AvgFGA3_Team1', 'AvgFGA3_Team2', 'AvgFTM_Team1',\n",
       "       'AvgFTM_Team2', 'AvgFTA_Team1', 'AvgFTA_Team2', 'AvgOR_Team1',\n",
       "       'AvgOR_Team2', 'AvgDR_Team1', 'AvgDR_Team2', 'AvgAst_Team1',\n",
       "       'AvgAst_Team2', 'AvgTO_Team1', 'AvgTO_Team2', 'AvgStl_Team1',\n",
       "       'AvgStl_Team2', 'AvgBlk_Team1', 'AvgBlk_Team2', 'AvgPF_Team1',\n",
       "       'AvgPF_Team2', 'FG%_Team1', 'FG%_Team2', 'FG3%_Team1', 'FG3%_Team2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "all_stats_df = pd.DataFrame(pd.read_csv('../resources/transformed_data/all_stats.csv'))\n",
    "all_stats_df = all_stats_df.drop(columns=['WTeamID'])\n",
    "all_stats_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97049, 12)\n",
      "(97049,)\n"
     ]
    }
   ],
   "source": [
    "# easy way to comment out unwanted features\n",
    "features_df = all_stats_df[['Season', \n",
    "#                             'DayNum', \n",
    "                            'Team1', 'Team2', \n",
    "#                             'Tourney', \n",
    "                            'WLoc', \n",
    "#                             'ScoreDiff',\n",
    "                            'Team1RankMean', 'Team2RankMean',\n",
    "#                             'Team1Seed', 'Team2Seed',\n",
    "                            'Team1FirstYear', 'Team2FirstYear',\n",
    "#                             'Team1LastYear', 'Team2LastYear',\n",
    "                            'WinCount_Team1', 'WinCount_Team2',\n",
    "#                             'LoseCount_Team1', 'LoseCount_Team2',\n",
    "                            'GameCount_Team1', 'GameCount_Team2',\n",
    "#                             'Win%_Team1', 'Win%_Team2',\n",
    "#                             'AvgScore_Team1', 'AvgScore_Team2',\n",
    "#                             'AvgFGM_Team1', 'AvgFGM_Team2', \n",
    "#                             'AvgFGA_Team1', 'AvgFGA_Team2',\n",
    "#                             'AvgFGM3_Team1', 'AvgFGM3_Team2', \n",
    "#                             'AvgFGA3_Team1', 'AvgFGA3_Team2',\n",
    "#                             'AvgFTM_Team1', 'AvgFTM_Team2', \n",
    "#                             'AvgFTA_Team1', 'AvgFTA_Team2',\n",
    "#                             'AvgOR_Team1', 'AvgOR_Team2', \n",
    "#                             'AvgDR_Team1', 'AvgDR_Team2',\n",
    "#                             'AvgAst_Team1', 'AvgAst_Team2', \n",
    "#                             'AvgTO_Team1', 'AvgTO_Team2',\n",
    "#                             'AvgStl_Team1', 'AvgStl_Team2', \n",
    "#                             'AvgBlk_Team1', 'AvgBlk_Team2',\n",
    "#                             'AvgPF_Team1', 'AvgPF_Team2',\n",
    "#                             'FG%_Team1', 'FG%_Team2',\n",
    "#                             'FG3%_Team1', 'FG3%_Team2',\n",
    "                            'WTeam',\n",
    "                           ]] \n",
    "\n",
    "# drop all NaNs\n",
    "features_df = features_df.dropna(how='any')\n",
    "# drop overcorrected rank \n",
    "features_df = features_df.loc[features_df.Team1RankMean < 500]\n",
    "features_df = features_df.loc[features_df.Team2RankMean < 500]\n",
    "\n",
    "# # shuffle and limit dataset (for time-consuming model training)\n",
    "# features_df = features_df.sample(frac=1).reset_index(drop=True)[:50000]\n",
    "# features_df = features_df.sample(frac=1).reset_index(drop=True)[:50000]\n",
    "\n",
    "\n",
    "# # change column type to test one hot encoder and scaler\n",
    "# features_df = features_df.astype({\n",
    "#                                   'Season':'str',\n",
    "#                                   'Team1':'str',\n",
    "#                                   'Team2':'str',\n",
    "#                                  })\n",
    "\n",
    "# select features and target\n",
    "target = features_df.pop('WTeam')\n",
    "selected_features = features_df\n",
    "print(selected_features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.70175732, -1.4099379 , -0.19242587, ...,  1.40594384,\n",
       "        -0.71502874,  0.03298801],\n",
       "       [-1.70175732,  0.5441819 ,  0.56725334, ...,  1.40594384,\n",
       "        -0.33564018, -0.34534499],\n",
       "       [-1.70175732,  0.47439191,  1.08149773, ..., -0.05430278,\n",
       "        -0.71502874,  0.03298801],\n",
       "       ...,\n",
       "       [ 0.3616575 , -0.72366964, -1.73515903, ...,  2.70394083,\n",
       "         1.56130266,  1.54632002],\n",
       "       [ 0.3616575 ,  0.2417586 ,  1.32693255, ...,  1.73044309,\n",
       "         1.56130266,  1.16798702],\n",
       "       [ 0.3616575 , -0.72366964, -1.15079041, ...,  1.40594384,\n",
       "         1.56130266,  1.54632002]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoder and scaler for pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), make_column_selector(dtype_include=np.number)),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), make_column_selector(dtype_include=object))\n",
    ")\n",
    "\n",
    "ct.fit_transform(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.model_selection import GridSearchCV, LeaveOneOut, RandomizedSearchCV\n",
    "# from sklearn import metrics\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# mlc = MLPClassifier(activation = 'relu', random_state=1, nesterovs_momentum=True)\n",
    "# loo = LeaveOneOut()\n",
    "# pipe = make_pipeline(ct, mlc)\n",
    "\n",
    "# params = {\n",
    "#           \"mlpclassifier__hidden_layer_sizes\":[(168,),(126,),(498,),(166,)],\n",
    "#           \"mlpclassifier__solver\" : ('sgd','adam'), \n",
    "#           \"mlpclassifier__alpha\": [0.001,0.0001],\n",
    "#           \"mlpclassifier__learning_rate_init\":[0.005,0.001]\n",
    "#          }\n",
    "\n",
    "# clf = RandomizedSearchCV(pipe, params, n_jobs=-1, verbose=3)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(selected_features, \n",
    "#                                                     target, stratify=target, \n",
    "#                                                     random_state=42)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# model = clf.best_estimator_\n",
    "# print(\"the best model and parameters are the following: {} \".format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model: \n",
    "\n",
    "MLPClassifier(alpha=0.001, hidden_layer_sizes=(168,),\n",
    "              learning_rate_init=0.005, random_state=1))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPClassifier(alpha=0.001, hidden_layer_sizes=(168,), random_state=1, solver='sgd')\n",
    " \n",
    "Test score: 0.7595148169668797\n",
    "\n",
    "Log loss: 0.8306158860092259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.61217232\n",
      "Iteration 2, loss = 0.53085917\n",
      "Iteration 3, loss = 0.51382161\n",
      "Iteration 4, loss = 0.50918211\n",
      "Iteration 5, loss = 0.50653723\n",
      "Iteration 6, loss = 0.50464102\n",
      "Iteration 7, loss = 0.50318430\n",
      "Iteration 8, loss = 0.50200659\n",
      "Iteration 9, loss = 0.50102367\n",
      "Iteration 10, loss = 0.50018767\n",
      "Iteration 11, loss = 0.49947350\n",
      "Iteration 12, loss = 0.49885607\n",
      "Iteration 13, loss = 0.49832531\n",
      "Iteration 14, loss = 0.49783135\n",
      "Iteration 15, loss = 0.49740570\n",
      "Iteration 16, loss = 0.49705519\n",
      "Iteration 17, loss = 0.49669926\n",
      "Iteration 18, loss = 0.49638214\n",
      "Iteration 19, loss = 0.49609890\n",
      "Iteration 20, loss = 0.49580649\n",
      "Iteration 21, loss = 0.49558074\n",
      "Iteration 22, loss = 0.49537413\n",
      "Iteration 23, loss = 0.49516708\n",
      "Iteration 24, loss = 0.49496091\n",
      "Iteration 25, loss = 0.49477736\n",
      "Iteration 26, loss = 0.49458150\n",
      "Iteration 27, loss = 0.49443392\n",
      "Iteration 28, loss = 0.49428567\n",
      "Iteration 29, loss = 0.49412690\n",
      "Iteration 30, loss = 0.49399714\n",
      "Iteration 31, loss = 0.49386135\n",
      "Iteration 32, loss = 0.49371102\n",
      "Iteration 33, loss = 0.49359094\n",
      "Iteration 34, loss = 0.49345953\n",
      "Iteration 35, loss = 0.49333739\n",
      "Iteration 36, loss = 0.49325152\n",
      "Iteration 37, loss = 0.49313574\n",
      "Iteration 38, loss = 0.49300024\n",
      "Iteration 39, loss = 0.49290218\n",
      "Iteration 40, loss = 0.49280930\n",
      "Iteration 41, loss = 0.49272068\n",
      "Iteration 42, loss = 0.49264236\n",
      "Iteration 43, loss = 0.49253828\n",
      "Iteration 44, loss = 0.49247035\n",
      "Iteration 45, loss = 0.49238097\n",
      "Iteration 46, loss = 0.49227427\n",
      "Iteration 47, loss = 0.49218939\n",
      "Iteration 48, loss = 0.49212112\n",
      "Iteration 49, loss = 0.49206515\n",
      "Iteration 50, loss = 0.49196584\n",
      "Iteration 51, loss = 0.49189672\n",
      "Iteration 52, loss = 0.49180704\n",
      "Iteration 53, loss = 0.49172093\n",
      "Iteration 54, loss = 0.49165806\n",
      "Iteration 55, loss = 0.49156679\n",
      "Iteration 56, loss = 0.49150271\n",
      "Iteration 57, loss = 0.49138790\n",
      "Iteration 58, loss = 0.49132565\n",
      "Iteration 59, loss = 0.49125630\n",
      "Iteration 60, loss = 0.49118574\n",
      "Iteration 61, loss = 0.49108246\n",
      "Iteration 62, loss = 0.49102124\n",
      "Iteration 63, loss = 0.49095595\n",
      "Iteration 64, loss = 0.49089031\n",
      "Iteration 65, loss = 0.49077698\n",
      "Iteration 66, loss = 0.49072681\n",
      "Iteration 67, loss = 0.49065577\n",
      "Iteration 68, loss = 0.49058735\n",
      "Iteration 69, loss = 0.49050876\n",
      "Iteration 70, loss = 0.49046465\n",
      "Iteration 71, loss = 0.49037653\n",
      "Iteration 72, loss = 0.49026507\n",
      "Iteration 73, loss = 0.49025802\n",
      "Iteration 74, loss = 0.49018649\n",
      "Iteration 75, loss = 0.49009422\n",
      "Iteration 76, loss = 0.49003947\n",
      "Iteration 77, loss = 0.48995531\n",
      "Iteration 78, loss = 0.48990326\n",
      "Iteration 79, loss = 0.48983437\n",
      "Iteration 80, loss = 0.48978451\n",
      "Iteration 81, loss = 0.48973550\n",
      "Iteration 82, loss = 0.48963243\n",
      "Iteration 83, loss = 0.48958156\n",
      "Iteration 84, loss = 0.48951158\n",
      "Iteration 85, loss = 0.48947865\n",
      "Iteration 86, loss = 0.48941740\n",
      "Iteration 87, loss = 0.48936449\n",
      "Iteration 88, loss = 0.48928622\n",
      "Iteration 89, loss = 0.48922950\n",
      "Iteration 90, loss = 0.48917137\n",
      "Iteration 91, loss = 0.48913317\n",
      "Iteration 92, loss = 0.48908443\n",
      "Iteration 93, loss = 0.48904758\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "-------------------\n",
      "Test score: 0.7579029798458559\n",
      "Log loss: 8.361829888418333\n",
      "\n",
      "-------------------\n",
      "\n",
      "[[9601 2884]\n",
      " [2990 8788]]\n",
      "\n",
      "-------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77     12485\n",
      "           1       0.75      0.75      0.75     11778\n",
      "\n",
      "    accuracy                           0.76     24263\n",
      "   macro avg       0.76      0.76      0.76     24263\n",
      "weighted avg       0.76      0.76      0.76     24263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, \n",
    "                                                    target, \n",
    "                                                    random_state=42)\n",
    "\n",
    "mlc = MLPClassifier(alpha=0.01, hidden_layer_sizes=(16,16), \n",
    "                    random_state=1, \n",
    "                    solver='sgd', \n",
    "#                     learning_rate='invscaling', \n",
    "#                     learning_rate_init=0.01,\n",
    "#                     power_t=.1,\n",
    "#                     max_iter=200, \n",
    "                    nesterovs_momentum=True, \n",
    "#                     batch_size=75,\n",
    "                    verbose=True)\n",
    "\n",
    "# mlc = MLPClassifier(alpha=0.001, hidden_layer_sizes=(14,14), \n",
    "#                     random_state=1, solver='sgd', learning_rate_init=0.01,)\n",
    "\n",
    "\n",
    "pipe = make_pipeline(ct, mlc)\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.predict_proba(X_test)\n",
    "preds = pipe.predict(X_test)\n",
    "train_score = pipe.score(X_train, y_train)\n",
    "test_score = pipe.score(X_test, y_test)\n",
    "loss_score = metrics.log_loss(y_test, preds)\n",
    "\n",
    "print('\\n-------------------')\n",
    "print(f'Test score: {test_score}')\n",
    "print(f'Log loss: {loss_score}')\n",
    "print('\\n-------------------\\n')\n",
    "print(metrics.confusion_matrix(y_test,preds))\n",
    "print('\\n-------------------\\n')\n",
    "print(metrics.classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_submit(model, df):\n",
    "    '''Creates and formats submission '''\n",
    "    preds = model.predict(df)\n",
    "    prob = [x[1] for x in model.predict_proba(df)]\n",
    "    \n",
    "    predict_df = pd.DataFrame({'Season':df['Season'],\n",
    "                  'Team1':df['Team1'],\n",
    "                  'Team2':df['Team2'],\n",
    "                  'Guess':preds,\n",
    "                  'Pred':prob}).round(3)\n",
    "\n",
    "    predict_df['ID'] = predict_df['Season'].astype(str) + '_' +\\\n",
    "                       predict_df['Team1'].astype(str) + '_' +\\\n",
    "                       predict_df['Team2'].astype(str)\n",
    "    \n",
    "    submit_df = predict_df[['ID','Guess','Pred']].set_index('ID')\n",
    "    \n",
    "#     submit_df['Pred'] = np.where(submit_df['Pred']<0.1, submit_df['Pred']-.1, submit_df['Pred'])\n",
    "#     submit_df['Pred'] = np.where(submit_df['Pred']>.9, submit_df['Pred']+.1, submit_df['Pred'])\n",
    "\n",
    "    submit_df.to_csv('../output/ml_march_madness_submission.csv')\n",
    "    \n",
    "    return submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_stats_submit_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2278, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stats_submit_df = pd.DataFrame(pd.read_csv('../resources/transformed_data/all_stats_submit.csv'))\n",
    "submit_df = all_stats_submit_df[selected_features.columns]\n",
    "submit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Guess</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021_1101_1104</th>\n",
       "      <td>0</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021_1101_1111</th>\n",
       "      <td>1</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021_1101_1116</th>\n",
       "      <td>0</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021_1101_1124</th>\n",
       "      <td>0</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021_1101_1140</th>\n",
       "      <td>0</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021_1452_1457</th>\n",
       "      <td>1</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021_1452_1458</th>\n",
       "      <td>1</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021_1455_1457</th>\n",
       "      <td>0</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021_1455_1458</th>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021_1457_1458</th>\n",
       "      <td>0</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Guess   Pred\n",
       "ID                          \n",
       "2021_1101_1104      0  0.166\n",
       "2021_1101_1111      1  0.782\n",
       "2021_1101_1116      0  0.179\n",
       "2021_1101_1124      0  0.105\n",
       "2021_1101_1140      0  0.198\n",
       "...               ...    ...\n",
       "2021_1452_1457      1  0.608\n",
       "2021_1452_1458      1  0.668\n",
       "2021_1455_1457      0  0.398\n",
       "2021_1455_1458      0  0.438\n",
       "2021_1457_1458      0  0.454\n",
       "\n",
       "[2278 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = format_submit(pipe, submit_df)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7ff382394910>),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7ff382394d90>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.01, hidden_layer_sizes=(16, 16),\n",
       "                               random_state=1, solver='sgd', verbose=True))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# filename = '../models/mlp_model_1.sav'\n",
    "# pickle.dump(pipe, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
